{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Progra_Files\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D,Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./Dataset/leapGestRecog/\"\n",
    "img_dims = (32, 32)\n",
    "\n",
    "lookup = dict()\n",
    "reverselookup = dict()\n",
    "count = 0\n",
    "\n",
    "for j in os.listdir(DATA_PATH+\"00/\"):\n",
    "    if not j.startswith('.'):\n",
    "        lookup[j] = count\t\n",
    "        reverselookup[count] = j\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '01_palm',\n",
       " 1: '02_l',\n",
       " 2: '03_fist',\n",
       " 3: '04_fist_moved',\n",
       " 4: '05_thumb',\n",
       " 5: '06_index',\n",
       " 6: '07_ok',\n",
       " 7: '08_palm_moved',\n",
       " 8: '09_c',\n",
       " 9: '10_down'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverselookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: Gesture dictionaries created.\n",
      "::: Images successfully loaded.\n",
      "Total number of images = 20000\n",
      "::: LABELS successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "x_data = []\n",
    "y_data = []\n",
    "datacount = 0 \n",
    "print (\"::: Gesture dictionaries created.\")\n",
    "\n",
    "for dir in glob(DATA_PATH + \"*\"):\n",
    "\tfor subdir in glob(dir + \"/*\"):\n",
    "\t\tcount = 0\n",
    "\t\tfor image in glob(subdir + \"/*.png\"):\n",
    "\t\t\timg = Image.open(image).convert('L')\n",
    "\t\t\timg = img.resize((320, 120))\n",
    "\t\t\timage_array = np.array(img)\n",
    "\t\t\tx_data.append(image_array)\n",
    "\t\t\tcount += 1\n",
    "\t\ty = np.full((count, 1), int(lookup[subdir.split(\"\\\\\")[-1]]))\n",
    "\t\ty_data.append(y)\n",
    "\t\tdatacount += count\n",
    "\t\t\n",
    "\t\t\n",
    "x_data = np.array(x_data, dtype = 'float32').reshape((datacount, 120, 320, 1))/255\n",
    "y_data = np.array(y_data).reshape(datacount, 1)\n",
    "print(\"::: Images successfully loaded.\")\n",
    "print(\"Total number of images =\", len(x_data))\n",
    "\n",
    "y_data = to_categorical(y_data)\n",
    "\n",
    "print(\"::: LABELS successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: TRAINING SET has been created.\n",
      "::: VALIDATION SET has been created.\n",
      "::: TESTING SET has been created.\n"
     ]
    }
   ],
   "source": [
    "x_train,x,y_train,y = train_test_split(x_data,y_data,test_size = 0.3)\n",
    "x_validate,x_test,y_validate,y_test = train_test_split(x,y,test_size = 0.5)\n",
    "\n",
    "print(\"::: TRAINING SET has been created.\")\n",
    "print(\"::: VALIDATION SET has been created.\")\n",
    "print(\"::: TESTING SET has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 58, 158, 32)       832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 77, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 11, 36, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 5760)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               737408    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 794,954\n",
      "Trainable params: 794,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(120, 320,1))) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jerin Paul\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 14000 samples, validate on 3000 samples\n",
      "Epoch 1/10\n",
      "14000/14000 [==============================] - 329s 24ms/step - loss: 0.3574 - acc: 0.8879 - val_loss: 0.0381 - val_acc: 0.9887\n",
      "Epoch 2/10\n",
      "14000/14000 [==============================] - 222s 16ms/step - loss: 0.0151 - acc: 0.9956 - val_loss: 0.0018 - val_acc: 0.9997\n",
      "Epoch 3/10\n",
      "14000/14000 [==============================] - 223s 16ms/step - loss: 0.0114 - acc: 0.9977 - val_loss: 0.0054 - val_acc: 0.9993\n",
      "Epoch 4/10\n",
      "14000/14000 [==============================] - 221s 16ms/step - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0025 - val_acc: 0.9993\n",
      "Epoch 5/10\n",
      "14000/14000 [==============================] - 221s 16ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0061 - val_acc: 0.9980\n",
      "Epoch 6/10\n",
      "14000/14000 [==============================] - 221s 16ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 4.3152e-04 - val_acc: 0.9997\n",
      "Epoch 7/10\n",
      "14000/14000 [==============================] - 221s 16ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 6.1850e-04 - val_acc: 0.9997\n",
      "Epoch 8/10\n",
      "14000/14000 [==============================] - 220s 16ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0028 - val_acc: 0.9997\n",
      "Epoch 9/10\n",
      "14000/14000 [==============================] - 242s 17ms/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.0045 - val_acc: 0.9997\n",
      "Epoch 10/10\n",
      "14000/14000 [==============================] - 274s 20ms/step - loss: 2.7524e-05 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd9fbefc50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=10, \n",
    "          batch_size=64, \n",
    "          validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 23s 8ms/step\n",
      "Accuracy:99.93333333333332\n"
     ]
    }
   ],
   "source": [
    "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
    "print(\"Accuracy:\" + str(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"./Models/GestureDetectionModel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    " # serialize weights to HDF5\n",
    "model.save_weights(\"./Models/GestureDetectionModel_weights.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
